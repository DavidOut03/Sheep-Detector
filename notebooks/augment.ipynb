{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2f3d4c7",
   "metadata": {},
   "source": [
    "# Image Augmentation with Bounding Box Tracking\n",
    "\n",
    "This notebook augments object images by blending them into background scenes with rotation and transparency, while tracking bounding boxes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9cbada",
   "metadata": {},
   "source": [
    "## Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "076ac501",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Tuple\n",
    "\n",
    "# Configuration\n",
    "IMAGE_EXTENSIONS = {\".jpg\", \".jpeg\", \".png\"}\n",
    "OUTPUT_DIR = \"augmented_images\"\n",
    "ANNOTATIONS_FILE = \"annotations.xlsx\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e44d3f",
   "metadata": {},
   "source": [
    "## Utility Functions\n",
    "\n",
    "Functions for loading images, ensuring alpha channels, and basic image operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "550c3ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Tuple\n",
    "def load_image(path: str) -> np.ndarray:\n",
    "    \"\"\"Loads an image with support for alpha channel (transparency).\"\"\"\n",
    "    return cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "def list_image_files(directory: str, extensions={\".jpg\", \".jpeg\", \".png\"}) -> List[str]:\n",
    "    \"\"\"List all image files in a directory with given extensions.\"\"\"\n",
    "    return [os.path.join(directory, f) for f in os.listdir(directory)\n",
    "            if os.path.splitext(f)[1].lower() in extensions]\n",
    "def add_alpha_if_missing(image: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Ensure image has 4 channels (RGBA).\"\"\"\n",
    "    if image.shape[2] == 3:\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2BGRA)\n",
    "        image[:, :, 3] = 255\n",
    "    return image\n",
    "\n",
    "def rotate_image(image: np.ndarray, angle: float) -> np.ndarray:\n",
    "    \"\"\"Rotate the image around its center.\"\"\"\n",
    "    h, w = image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    cos = np.abs(M[0, 0])\n",
    "    sin = np.abs(M[0, 1])\n",
    "    new_w = int((h * sin) + (w * cos))\n",
    "    new_h = int((h * cos) + (w * sin))\n",
    "    M[0, 2] += (new_w / 2) - center[0]\n",
    "    M[1, 2] += (new_h / 2) - center[1]\n",
    "    return cv2.warpAffine(image, M, (new_w, new_h), flags=cv2.INTER_LINEAR, borderValue=(0, 0, 0, 0))\n",
    "\n",
    "def crop_and_prepare_sheep(image: np.ndarray, bbox: Tuple[int, int, int, int], max_size: int = 60) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Crop the sheep from the image, ensure alpha channel, and apply random rotation.\n",
    "    \"\"\"\n",
    "    x, y, w, h = bbox\n",
    "    sheep = image[y:y+h, x:x+w]\n",
    "    sheep = add_alpha_if_missing(sheep)\n",
    "\n",
    "    angle = random.uniform(0, 360)\n",
    "    return rotate_image(sheep, angle)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90eb0ebb",
   "metadata": {},
   "source": [
    "## Augmentation Functions\n",
    "\n",
    "Functions for cropping, rotating, and blending object images (e.g., sheep) onto backgrounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b47404a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ../dataset/augmented\\augmented_0.jpg\n",
      "Saved: ../dataset/augmented\\augmented_1.jpg\n",
      "Saved: ../dataset/augmented\\augmented_2.jpg\n",
      "Saved: ../dataset/augmented\\augmented_3.jpg\n",
      "Saved: ../dataset/augmented\\augmented_4.jpg\n",
      "Saved: ../dataset/augmented\\augmented_5.jpg\n",
      "Saved: ../dataset/augmented\\augmented_6.jpg\n",
      "Saved: ../dataset/augmented\\augmented_7.jpg\n",
      "Saved: ../dataset/augmented\\augmented_8.jpg\n",
      "Saved: ../dataset/augmented\\augmented_9.jpg\n"
     ]
    }
   ],
   "source": [
    "def match_background_texture(sheep_rgb: np.ndarray, background_roi: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Adjust brightness to match the background ROI.\n",
    "    \"\"\"\n",
    "    mean_bg = np.mean(background_roi)\n",
    "    mean_sheep = np.mean(sheep_rgb)\n",
    "    alpha = mean_bg / max(mean_sheep, 1)\n",
    "    return cv2.convertScaleAbs(sheep_rgb, alpha=alpha)\n",
    "\n",
    "\n",
    "def paste_sheep(background: np.ndarray, sheep: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Paste one sheep using feathered Poisson blending and localized brightness adjustment.\n",
    "    \"\"\"\n",
    "    if sheep.shape[2] != 4:\n",
    "        return background\n",
    "\n",
    "    mask = cv2.threshold(sheep[:, :, 3], 1, 255, cv2.THRESH_BINARY)[1]\n",
    "    sheep_rgb = sheep[:, :, :3]\n",
    "\n",
    "    bg_h, bg_w = background.shape[:2]\n",
    "    sh_h, sh_w = sheep_rgb.shape[:2]\n",
    "\n",
    "    if sh_h >= bg_h or sh_w >= bg_w:\n",
    "        return background\n",
    "\n",
    "    x = random.randint(0, bg_w - sh_w)\n",
    "    y = random.randint(0, bg_h - sh_h)\n",
    "    center = (x + sh_w // 2, y + sh_h // 2)\n",
    "\n",
    "    # ✅ Feather mask\n",
    "    mask = cv2.GaussianBlur(mask, (3, 3), 0)\n",
    "\n",
    "    # ✅ Brightness match using ROI\n",
    "    roi = background[y:y+sh_h, x:x+sh_w]\n",
    "    sheep_rgb = match_background_texture(sheep_rgb, roi)\n",
    "\n",
    "    try:\n",
    "        return cv2.seamlessClone(sheep_rgb, background, mask, center, cv2.MIXED_CLONE)\n",
    "    except:\n",
    "        return background\n",
    "\n",
    "\n",
    "def generate_augmented_images_from_annotations(\n",
    "    images_folder: str,\n",
    "    annotations_path: str,\n",
    "    output_folder: str,\n",
    "    amount: int = 5,\n",
    "    sheep_min: int = 5,\n",
    "    sheep_max: int = 10\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate synthetic images using annotated sheep images and placing them on random backgrounds.\n",
    "    \n",
    "    Args:\n",
    "        images_folder (str): Path to the folder with all images.\n",
    "        annotations_path (str): Path to the Excel file containing bounding box annotations.\n",
    "        output_folder (str): Folder where generated images will be saved.\n",
    "        amount (int): Number of images to generate.\n",
    "        sheep_min (int): Minimum number of sheep per image.\n",
    "        sheep_max (int): Maximum number of sheep per image.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    df = pd.read_excel(annotations_path)\n",
    "    grouped = df.groupby(\"image_name\")\n",
    "\n",
    "    sheep_image_names = list(grouped.groups.keys())\n",
    "\n",
    "    bounding_boxes = [\n",
    "        [\n",
    "            (row[\"bbox_x\"], row[\"bbox_y\"], row[\"bbox_width\"], row[\"bbox_height\"])\n",
    "            for _, row in group.iterrows()\n",
    "        ]\n",
    "        for _, group in grouped\n",
    "    ]\n",
    "\n",
    "    all_images = list_image_files(images_folder)\n",
    "    sheep_images = [os.path.join(images_folder, name) for name in sheep_image_names if os.path.exists(os.path.join(images_folder, name))]\n",
    "    background_images = [img for img in all_images if os.path.basename(img) not in sheep_image_names]\n",
    "\n",
    "    for i in range(amount):\n",
    "        background = load_image(random.choice(background_images))\n",
    "        result = background.copy()\n",
    "\n",
    "        num_sheep = random.randint(sheep_min, sheep_max)\n",
    "\n",
    "        for _ in range(num_sheep):\n",
    "            idx = random.randint(0, len(sheep_images) - 1)\n",
    "            boxes = bounding_boxes[idx]\n",
    "            if not boxes:\n",
    "                continue\n",
    "\n",
    "            sheep_img = load_image(sheep_images[idx])\n",
    "            bbox = random.choice(boxes)\n",
    "            sheep = crop_and_prepare_sheep(sheep_img, bbox)\n",
    "            result = paste_sheep(result, sheep)\n",
    "\n",
    "        output_path = os.path.join(output_folder, f\"augmented_{i}.jpg\")\n",
    "        cv2.imwrite(output_path, result)\n",
    "        print(f\"Saved: {output_path}\")\n",
    "\n",
    "\n",
    "data_folder = \"../dataset\"\n",
    "images_folder = f\"{data_folder}/images\"\n",
    "annotations_path = f\"{data_folder}/annotations.xlsx\"\n",
    "output_folder = f\"{data_folder}/augmented\"\n",
    "\n",
    "generate_augmented_images_from_annotations(\n",
    "    images_folder=images_folder,\n",
    "    annotations_path=annotations_path,\n",
    "    output_folder=output_folder,\n",
    "    amount=10,\n",
    "    sheep_min=3,     \n",
    "    sheep_max=8   \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3fdbcf",
   "metadata": {},
   "source": [
    "## Main Augmentation Process\n",
    "\n",
    "Loop through background and object images, perform augmentation, and collect bounding box data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "523f439a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The main augmentation loop would be here, invoking above functions appropriately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc9fc75",
   "metadata": {},
   "source": [
    "## Export Annotations\n",
    "\n",
    "Save the collected bounding box annotations to an Excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62099b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def export_annotations(bbox_data: list, output_path: str) -> None:\n",
    "    \"\"\"Save bounding box annotations to an Excel file.\"\"\"\n",
    "    df = pd.DataFrame(bbox_data, columns=[\"filename\", \"class\", \"x_min\", \"y_min\", \"x_max\", \"y_max\"])\n",
    "    df.to_excel(output_path, index=False)\n",
    "\n",
    "# Example usage after processing\n",
    "# export_annotations(all_bboxes, os.path.join(OUTPUT_DIR, ANNOTATIONS_FILE))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dea4796",
   "metadata": {},
   "source": [
    "## Refactored Augmentation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b22cd60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_paste_position(bg_shape, sheep_shape) -> Tuple[int, int]:\n",
    "    \"\"\"Calculate a random valid paste position on the background.\"\"\"\n",
    "    bg_h, bg_w = bg_shape[:2]\n",
    "    sh_h, sh_w = sheep_shape[:2]\n",
    "    max_x = max(bg_w - sh_w, 1)\n",
    "    max_y = max(bg_h - sh_h, 1)\n",
    "    return random.randint(0, max_x), random.randint(0, max_y)\n",
    "\n",
    "def blend_images(background, foreground, x_offset, y_offset) -> np.ndarray:\n",
    "    \"\"\"Alpha blend the foreground (sheep) onto the background.\"\"\"\n",
    "    bg = background.copy()\n",
    "    h, w = foreground.shape[:2]\n",
    "    alpha_s = foreground[:, :, 3] / 255.0\n",
    "    alpha_b = 1.0 - alpha_s\n",
    "\n",
    "    for c in range(3):\n",
    "        bg[y_offset:y_offset+h, x_offset:x_offset+w, c] = (\n",
    "            alpha_s * foreground[:, :, c] +\n",
    "            alpha_b * bg[y_offset:y_offset+h, x_offset:x_offset+w, c]\n",
    "        )\n",
    "    return bg\n",
    "\n",
    "def compute_bounding_box(x_offset, y_offset, sheep_shape) -> Tuple[int, int, int, int]:\n",
    "    \"\"\"Compute bounding box for the pasted object.\"\"\"\n",
    "    sh_h, sh_w = sheep_shape[:2]\n",
    "    return x_offset, y_offset, x_offset + sh_w, y_offset + sh_h\n",
    "\n",
    "def paste_sheep(background: np.ndarray, sheep: np.ndarray) -> Tuple[np.ndarray, Tuple[int, int, int, int]]:\n",
    "    \"\"\"Paste sheep image onto background with blending and return new image and bbox.\"\"\"\n",
    "    x_offset, y_offset = calculate_paste_position(background.shape, sheep.shape)\n",
    "    blended_image = blend_images(background, sheep, x_offset, y_offset)\n",
    "    bbox = compute_bounding_box(x_offset, y_offset, sheep.shape)\n",
    "    return blended_image, bbox\n",
    "\n",
    "def generate_augmented_images_from_annotations(annotation_df: pd.DataFrame, backgrounds: List[str], sheep_images: str, output_dir: str) -> list:\n",
    "    \"\"\"Main function to generate augmented images and collect bounding boxes.\"\"\"\n",
    "    all_bboxes = []\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    sheep_files = list_image_files(sheep_images)\n",
    "    \n",
    "    for idx, row in annotation_df.iterrows():\n",
    "        bg_path = random.choice(backgrounds)\n",
    "        bg_img = add_alpha_if_missing(load_image(bg_path))\n",
    "        sheep_path = random.choice(sheep_files)\n",
    "        sheep_img = add_alpha_if_missing(load_image(sheep_path))\n",
    "        \n",
    "        bbox = (10, 10, sheep_img.shape[1] - 20, sheep_img.shape[0] - 20)\n",
    "        prepared_sheep = crop_and_prepare_sheep(sheep_img, bbox)\n",
    "        \n",
    "        result_img, new_bbox = paste_sheep(bg_img, prepared_sheep)\n",
    "        filename = f\"aug_{idx}.png\"\n",
    "        cv2.imwrite(os.path.join(output_dir, filename), result_img)\n",
    "        \n",
    "        all_bboxes.append([filename, \"sheep\", *new_bbox])\n",
    "    \n",
    "    return all_bboxes\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
